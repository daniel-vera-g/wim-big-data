{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "1. Initialize Spaark session connecting to the Postgres DB\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark # only run after findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"MusicBrainz PostgreSQL Connection\") \\\n",
    "    .config(\"spark.jars\", \"/Users/d.veragillard/edu/semester/WIM-1/big-data-advanced-database/bd-project/postgresql-42.7.1.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Database connection properties\n",
    "database_url = \"jdbc:postgresql://localhost:5432/musicbrainz\"\n",
    "properties = {\"user\": \"musicbrainz\", \"password\": \"musicbrainz\", \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "# TODO Explore / Clean data\n",
    "\n",
    "# Reading data from PostgreSQL\n",
    "df = spark.read.jdbc(url=database_url, table=\"artist\", properties=properties)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading tables from PostgreSQL\n",
    "def load_table(table_name):\n",
    "    return spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://localhost:5432/musicbrainz\") \\\n",
    "        .option(\"dbtable\", table_name) \\\n",
    "        .option(\"user\", \"musicbrainz\") \\\n",
    "        .option(\"password\", \"musicbrainz\") \\\n",
    "        .load()\n",
    "\n",
    "# Load necessary tables\n",
    "artist_df = load_table(\"artist\")\n",
    "release_df = load_table(\"release\")\n",
    "recording_df = load_table(\"recording\")\n",
    "instrument_df = load_table(\"instrument\")\n",
    "work_df = load_table(\"work\")\n",
    "\n",
    "# Joining and creating features\n",
    "# Example: Joining artist and recording tables\n",
    "# joined_df = recording_df.join(artist_df, recording_df.artist_credit == artist_df.id, \"inner\")\n",
    "\n",
    "# Feature Engineering\n",
    "# Example: Extracting year from date and calculating age of recording\n",
    "# from pyspark.sql.functions import year, current_date, datediff\n",
    "# joined_df = joined_df.withColumn(\"release_year\", year(col(\"release_date\")))\n",
    "# joined_df = joined_df.withColumn(\"age_of_recording\", datediff(current_date(), col(\"release_date\")))\n",
    "\n",
    "# Show the DataFrame\n",
    "# joined_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
